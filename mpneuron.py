# -*- coding: utf-8 -*-
"""MPNeuron.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AFLoe3KOHkknxZX2VOE5hfv_yNeXqcrh

###Dataset
"""

import sklearn.datasets
import numpy as np

breast_cancer = sklearn.datasets.load_breast_cancer()

x = breast_cancer.data
y = breast_cancer.target

print(x)
print(y)

print(x.shape , y.shape)

import pandas as pd

data = pd.DataFrame(breast_cancer.data , columns = breast_cancer.feature_names)

##adding output to the dataset at the end
data['output'] = breast_cancer.target

data.head()

data.describe()

print(data['output'].value_counts())

print(breast_cancer.target_names)

data.groupby('output').mean()



"""###Splitting Datasets"""

from sklearn.model_selection import train_test_split

x = data.drop('output',axis=1)  ##axis=1 for columns and 0 for rows
y = data['output']

#It is convinient if the dataset type is dataframe 
type(x)

x_train , x_test , y_train , y_test = train_test_split(x, y, test_size = 0.25)

print(x.shape,x_train.shape,x_test.shape)

print(y.mean(),y_train.mean(),y_test.mean())

#stratify keeps the spliiting equal in terms 0 and 1 output or very less error can be checked using mean function
# If we dont set the random_state to any integer , after every run it will change the spliiting of dataset which we dont want
x_train , x_test , y_train , y_test = train_test_split(x, y, test_size = 0.1, stratify = y, random_state = 1)

print(x.mean(),x_train.mean(),x_test.mean())



"""###Binarization of Dataset"""

import matplotlib.pyplot as plt

plt.plot(x_train.T,'*')
plt.xticks(rotation='vertical')
plt.show()

##MP Neuron only takes binarised inputs
x_train_binary = x_train['mean area'].map(lambda x:0 if x<1000 else 1)

plt.plot(x_train_binary,'*')
plt.show()

##making all the inputs in the binary form using pandas function pd.cut which cuts the values in bins
x_binarised_train = x_train.apply(pd.cut,bins=2,labels=[1,0])

plt.plot(x_binarised_train.T,'*')
plt.xticks(rotation='vertical')
plt.show()

x_binarised_test = x_test.apply(pd.cut,bins=2,labels=[1,0])

type(x_binarised_test)

##changing the type to numpy array
x_binarised_test = x_binarised_test.values
x_binarised_train = x_binarised_train.values

type(x_binarised_test)



"""#MP Neuron Model"""

from random import randint

##for any b
b=4

i=randint(0,x_binarised_train.shape[0])

print('For row',i)
if(np.sum(x_binarised_train[100,:])>=b):
  print('MP Neuron inference is Malignant')
else:
  print('MP Neuron inference is Benign')

if(y_train[i]==1):
  print('True output is Malignant')
else:
  print('True output is Benign')

b=4

y_pred_train = []
accurate_rows = 0
for X,Y in zip(x_binarised_train,y_train):
  y_pred = (np.sum(X)>=b)
  y_pred_train.append(np.sum(X)>=b)
  accurate_rows += (Y==y_pred)

print(accurate_rows,accurate_rows/x_binarised_train.shape[0])

##Accuracy we got for b=4 is 15% which is very low considering the base line so we will iterate b for all x
y_z=list()
for b in range(x_binarised_train.shape[1]+1):
  y_pred_train = []
  accurate_rows = 0

  for X,Y in zip(x_binarised_train,y_train):
    y_pred = (np.sum(X)>=b)
    y_pred_train.append(np.sum(X)>=b)
    accurate_rows += (Y==y_pred)
  y_z.append((accurate_rows/x_binarised_train.shape[0]))
  print(b,accurate_rows/x_binarised_train.shape[0])
x_z=list()
for i in range(0,31):
  x_z.append(i)
#len(y_z)
plt.plot(x_z,y_z)
plt.ylabel('Accuracy')
plt.xlabel('Threshold')
plt.show()

## still very low accuracy , which means the binarisation is not correct so we will change it as the malignant is the dominant part
for b in range(x_binarised_train.shape[1]+1):
  y_pred_train = []
  accurate_rows = 0
  for X,Y in zip(x_binarised_train,y_train):
    y_pred = (np.sum(X)>=b)
    y_pred_train.append(np.sum(X)>=b)
    accurate_rows += (Y==y_pred)

  print(b,accurate_rows/x_binarised_train.shape[0])
  ##Now the highest accuracy we are getting is approx 84.9 for b=28

from sklearn.metrics import accuracy_score

##As for train b=28 gives highest accuracy now we will test it into test data
b=28

y_pred_test = []

for X in x_binarised_test:
  y_pred = (np.sum(X)>=b)
  y_pred_test.append(y_pred)
accuracy = accuracy_score(y_pred_test,y_test)
print(b,accuracy)
##So for the best b in the training set the accuracy in test set is 78.9% which is less than what we got in training set(84.5%)

"""#MP Neuron Class

###Demonstration of MP Neuron and its functions as a class
"""

class MP_Neuron:
  def __init__(self):
    self.b = None
  
  def model(self,x):
    return (sum(x)>=self.b)
  
  def predict(self,x):
    y=[]
    for X in x:
      result = self.model(X)
      y.append(result)
    return np.array(y)

  def fit(self,x,y):
    accuracy={}

    for b in range(x.shape[1]+1):
      self.b = b
      y_pred = self.predict(x)
      accuracy[b] = accuracy_score(y_pred,y)

    best_b = max(accuracy , key=accuracy.get)
    self.b = best_b

    print('Optimal value of b is',best_b)
    print('Highest Accuracy obtained is ',accuracy[best_b])

mp_neuron = MP_Neuron()
mp_neuron.fit(x_binarised_train,y_train)

y_test_pred = mp_neuron.predict(x_binarised_test)
accuracy_test = accuracy_score(y_test_pred,y_test)

print(accuracy_test)



"""#Perceptron Class

$y=1,\mbox{if}\sum_i w_i x_i >=b$

$y=0,\mbox{otherwise}\$
"""

x_train = x_train.values
x_test = x_test.values

type(x_train)

class Perceptron:
  def __init__(self):
    self.w=None
    self.b=None
  
  def model(self,x):
    return 1 if(np.dot(self.w,x)>=self.b) else 0

  def predict(self,x):
    y=[]
    for X in x:
      result = self.model(X)
      y.append(result)
    return np.array(y)
  
  def fit(self,x,y,epochs=1,lr=1):
    self.w = np.ones(x.shape[1])
    self.b=0

    accuracy = {}
    max_accuracy = 0
    wt_matrix = []

    for i in range(epochs):
      for X,Y in zip(x,y):
        y_pred = self.model(X)
        if Y==1 and y_pred==0:
          self.w = self.w + lr*X
          self.b = self.b + lr*1
        elif Y==0 and y_pred==1:
          self.w = self.w - lr*X
          self.b = self.b - lr*1

      wt_matrix.append(self.w)
      accuracy[i] = accuracy_score(self.predict(x),y)
      if(accuracy[i]>max_accuracy):
        max_accuracy = accuracy[i]
        checkptw = self.w
        checkptb = self.b
    print(max_accuracy)

    plt.plot(list(accuracy.values()))
    plt.ylim([0,1])
    plt.show()
    return np.array(wt_matrix)

perceptron = Perceptron()

##perceptron model takes real values inputs , so x_train not x_binaerised_train
wt_matrix = perceptron.fit(x_train,y_train,10000,0.0001)

plt.plot(perceptron.w)
plt.show()

y_pred_train = perceptron.predict(x_train)
print(accuracy_score(y_pred_train,y_train))

y_pred_test = perceptron.predict(x_test)
print(accuracy_score(y_pred_test,y_test))

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
from matplotlib import animation, rc
from IPython.display import HTML

# First set up the figure, the axis, and the plot element we want to animate
fig, ax = plt.subplots()

ax.set_xlim(( 0, wt_matrix.shape[1]))
ax.set_ylim((-5,5))

line, = ax.plot([], [], lw=2)

# animation function. This is called sequentially
def animate(i):
    x = list(range(wt_matrix.shape[1]))
    y = wt_matrix[i,:]
    line.set_data(x, y)
    return (line,)

# call the animator. blit=True means only re-draw the parts that have changed.
anim = animation.FuncAnimation(fig, animate,frames=100, interval=20, blit=True)

HTML(anim.to_html5_video())

